{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packeges\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from random import randint\n",
    "from random import sample\n",
    "from random import shuffle\n",
    "import pickle\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load prepared data\n",
    "with open('train test split data.pkl', 'rb') as f: \n",
    "    X_train, X_val, y_train, y_val =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.arange(125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation\n",
    "\n",
    "augment = A.Compose([\n",
    "\n",
    "    A.HorizontalFlip(always_apply = False, p = 0.5),\n",
    "\n",
    "    A.VerticalFlip(always_apply = False, p = 0.1),\n",
    "\n",
    "    A.RGBShift(r_shift_limit = np.random.uniform(0.01, 0.1), \n",
    "            g_shift_limit = np.random.uniform(0.01, 0.1), \n",
    "            b_shift_limit = np.random.uniform(0.01, 0.1),\n",
    "            always_apply = False, p = 0.5),\n",
    "\n",
    "    A.RandomBrightnessContrast(brightness_limit = np.random.uniform(0.1, 0.2), \n",
    "                                contrast_limit = np.random.uniform(0.1, 0.5), \n",
    "                                brightness_by_max = [True, False][randint(0,1)],\n",
    "                                always_apply = False, p = 0.2),\n",
    "\n",
    "    A.ColorJitter(brightness = np.random.uniform(0, 0.6), \n",
    "                  contrast = np.random.uniform(0, 0.6), \n",
    "                  saturation = np.random.uniform(0, 0.6), \n",
    "                  hue = np.random.uniform(0, 0.6), \n",
    "                  always_apply = False, p = 0.5),\n",
    "\n",
    "    A.RandomGamma(gamma_limit = (80, 200), always_apply = False, p = 0.2),\n",
    "\n",
    "    A.ToGray(always_apply = False, p = 0.2),\n",
    "\n",
    "    A.ToSepia(always_apply = False, p = 0.2),\n",
    "\n",
    "    A.Transpose(always_apply = False, p = 0.3),\n",
    "\n",
    "    A.ElasticTransform(alpha = randint(1,4), sigma = randint(1,4), \n",
    "                        alpha_affine = randint(1,4), \n",
    "                        interpolation = randint(0, 4), \n",
    "                        border_mode = randint(0, 4), \n",
    "                        value = np.random.uniform(0, 1), \n",
    "                        mask_value = np.random.uniform(0, 1),\n",
    "                        always_apply = False, p = 0.2),\n",
    "\n",
    "    A.ShiftScaleRotate(shift_limit = np.random.uniform(0, 0.15), \n",
    "                        scale_limit = np.random.uniform(0, 0.15), \n",
    "                        rotate_limit = 45, interpolation = randint(0, 4), \n",
    "                        border_mode = randint(0, 4), \n",
    "                        value = np.random.uniform(0, 1), \n",
    "                        mask_value = np.random.uniform(0, 1), \n",
    "                        shift_limit_x = None, shift_limit_y = None,\n",
    "                        always_apply = False, p = 0.2),\n",
    "                     \n",
    "    A.Resize(224, 224, interpolation = 2, always_apply=True),\n",
    "\n",
    "    A.ToFloat(max_value=255, always_apply=True)\n",
    "\n",
    "])\n",
    "\n",
    "resize = A.Compose([\n",
    "          A.Resize(224, 224, interpolation = 2, always_apply=True),\n",
    "          A.ToFloat(max_value=255, always_apply=True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch generator\n",
    "\n",
    "class batch_generator(Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size, augmentations, shuffle):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augmentations\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if(self.shuffle):\n",
    "            nums = sample(range(len(self.x)), self.batch_size)\n",
    "            batch_x = [self.x[num_i] for num_i in nums]\n",
    "            batch_y = [self.y[num_i] for num_i in nums]\n",
    "        else:\n",
    "            batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        return np.stack([\n",
    "            self.augment(image = np.uint8(x * 255))[\"image\"] for x in batch_x\n",
    "        ], axis=0), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load VGG without last layers\n",
    "from keras.applications import VGG19\n",
    "pretrained = VGG19(input_shape = (224, 224,3), include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pretrained.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(pretrained)\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(125, activation=\"relu\", kernel_regularizer = keras.regularizers.l1_l2(l1 = 0.01)))\n",
    "\n",
    "model.add(Dense(125, activation='softmax'))\n",
    "\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 7, 7, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 125)               3136125   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 125)               15750     \n",
      "=================================================================\n",
      "Total params: 23,176,259\n",
      "Trainable params: 3,151,875\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"chk.hdf5\", monitor='val_categorical_accuracy', verbose=1,\n",
    "    save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = keras.optimizers.Nadam(learning_rate=0.001), \n",
    "              metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(train_gen, epochs = 50, \n",
    "#                              validation_data = val_gen, \n",
    "#                              validation_steps = 203, callbacks=[checkpoint1, checkpoint2]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
